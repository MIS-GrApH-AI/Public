{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data into Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the data  \n",
    "The data were obtaind from Physionet, where the following abstract describes the data: \"MIMIC-III is a large, freely-available database comprising deidentified health-related data associated with over 40,000 patients who stayed in critical care units of the Beth Israel Deaconess Medical Center between 2001 and 2012 [1]. The MIMIC-III Clinical Database is available on PhysioNet (doi: 10.13026/C2XW26). Though deidentified, MIMIC-III contains detailed information regarding the care of real patients, and as such requires credentialing before access. To allow researchers to ascertain whether the database is suitable for their work, we have manually curated a demo subset, which contains information for 100 patients also present in the MIMIC-III Clinical Database. <strong>Notably, the demo dataset does not include free-text notes.</strong>\"\n",
    "\n",
    "### Data reference:\n",
    "Johnson, A. E. W., Pollard, T. J., Shen, L., Lehman, L. H., Feng, M., Ghassemi, M., Moody, B., Szolovits, P., Celi, L. A., & Mark, R. G. (2016). MIMIC-III, a freely accessible critical care database. Scientific data, 3, 160035.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import MIMIC III Demo 1.4 Data to into a graph database\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data downloaded from https://physionet.org/content/mimiciii-demo/1.4/ on 11 February, 2021.\n",
    "The downloaded data consisted of the following 28 files:\n",
    "- ADMISSIONS.csv\n",
    "- CALLOUT.csv\n",
    "- CAREGIVERS.csv\n",
    "- CHARTEVENTS.csv\n",
    "- CPTEVENTS.csv\n",
    "- DATETIMEEVENTS.csv\n",
    "- D_CPT.csv\n",
    "- DIAGNOSES_ICD.csv\n",
    "- D_ICD_DIAGNOSES.csv\n",
    "- D_ICD_PROCEDURES.csv\n",
    "- D_ITEMS.csv\n",
    "- D_LABITEMS.csv\n",
    "- DRGCODES.csv\n",
    "- ICUSTAYS.csv\n",
    "- INPUTEVENTS_CV.csv\n",
    "- INPUTEVENTS_MV.csv\n",
    "- LABEVENTS.csv\n",
    "- LICENSE.txt\n",
    "- MICROBIOLOGYEVENTS.csv\n",
    "- NOTEEVENTS.csv\n",
    "- OUTPUTEVENTS.csv\n",
    "- PATIENTS.csv\n",
    "- PRESCRIPTIONS.csv\n",
    "- PROCEDUREEVENTS_MV.csv\n",
    "- PROCEDURES_ICD.csv\n",
    "- SERVICES.csv\n",
    "- SHA256SUMS.txt\n",
    "- TRANSFERS.csv\n",
    "\n",
    "The CSV files were placed in the Import folder of the GraphEHR_Proof-of-concept Neo4j database to make them readily available for import into the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write cypher commands for nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['row_id', 'subject_id', 'hadm_id', 'admittime', 'dischtime', 'deathtime', 'admission_type', 'admission_location', 'discharge_location', 'insurance', 'language', 'religion', 'marital_status', 'ethnicity', 'edregtime', 'edouttime', 'diagnosis', 'hospital_expire_flag', 'has_chartevents_data']\n"
     ]
    }
   ],
   "source": [
    "# Specify the location of the CSV files to import. This is the path to the /import folder in your Neo4j database. \n",
    "# Make sure your path ends with a backslash\n",
    "path = '/home/tim/.config/Neo4j Desktop/Application/relate-data/dbmss/dbms-0d5f0a02-7d73-4462-a47e-2a074de0b766/import/'\n",
    "\n",
    "# Create a list of all CSV files to import\n",
    "csv_files = ['ADMISSIONS.csv', 'CALLOUT.csv', 'CAREGIVERS.csv', 'CHARTEVENTS.csv', 'CPTEVENTS.csv', 'DATETIMEEVENTS.csv', 'D_CPT.csv', 'DIAGNOSES_ICD.csv', 'D_ICD_DIAGNOSES.csv', 'D_ICD_PROCEDURES.csv', 'D_ITEMS.csv', 'D_LABITEMS.csv', 'DRGCODES.csv', 'ICUSTAYS.csv', 'INPUTEVENTS_CV.csv', 'INPUTEVENTS_MV.csv', 'LABEVENTS.csv', 'MICROBIOLOGYEVENTS.csv', 'NOTEEVENTS.csv', 'OUTPUTEVENTS.csv', 'PATIENTS.csv', 'PRESCRIPTIONS.csv', 'PROCEDUREEVENTS_MV.csv', 'PROCEDURES_ICD.csv', 'SERVICES.csv', 'TRANSFERS.csv']\n",
    "\n",
    "# Create a dictionary with file names as keys and the list of headers for each file as values \n",
    "headers_dict = {}\n",
    "for file in csv_files:\n",
    "    headers = pd.read_csv(path+file, nrows=1)\n",
    "    headers = headers.columns.tolist()\n",
    "    if not file in headers_dict:\n",
    "        headers_dict[file] = headers\n",
    "        \n",
    "# Inspect an example item in the dictionary\n",
    "print(headers_dict['ADMISSIONS.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'USING PERIODIC COMMIT 100000 LOAD CSV FROM \"file:///ADMISSIONS.csv\" AS COLUMN CREATE (n:Admissions {row_id:COLUMN[0], subject_id:COLUMN[1], hadm_id:COLUMN[2], admittime:COLUMN[3], dischtime:COLUMN[4], deathtime:COLUMN[5], admission_type:COLUMN[6], admission_location:COLUMN[7], discharge_location:COLUMN[8], insurance:COLUMN[9], language:COLUMN[10], religion:COLUMN[11], marital_status:COLUMN[12], ethnicity:COLUMN[13], edregtime:COLUMN[14], edouttime:COLUMN[15], diagnosis:COLUMN[16], hospital_expire_flag:COLUMN[17], has_chartevents_data:COLUMN[18]})'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a function that writes the string for a cypher command\n",
    "# to create nodes from each CSV file\n",
    "\n",
    "def csv_to_node(csv_file):\n",
    "    \n",
    "    # Create the node label based on the CSV file name. Place it in title case and remove the '.csv' suffix\n",
    "    label= csv_file[:-4].title() \n",
    "    \n",
    "    # Convert the CSV's headers into node properties\n",
    "    properties = '{'\n",
    "    col_index = 0\n",
    "    for header in headers_dict[csv_file]:\n",
    "        header = header.lower()\n",
    "        properties = properties+header+':COLUMN['+str(col_index)+'], '\n",
    "        properties = properties.replace('.','_')\n",
    "        col_index += 1\n",
    "    properties = properties[:-2]+'}' # Delete last comma of the list and add the ending curly bracket\n",
    "    \n",
    "    # Compile the complete cypher command\n",
    "    cypher = '''USING PERIODIC COMMIT 100000 LOAD CSV FROM \"file:///{csv_file}\" AS COLUMN CREATE (n:{label} {properties})'''.format(csv_file=csv_file, label=label, properties=properties)\n",
    "    return cypher\n",
    "\n",
    "# Generate the cypher code for a single csv file to test in the Neo4j browser\n",
    "csv_to_node('ADMISSIONS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize a connection to the neo4j database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "driver=GraphDatabase.driver(uri=\"bolt://localhost:7687\", auth=('neo4j','Gr@ph3HR'))\n",
    "session=driver.session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all nodes\n",
    "for csv_name in csv_files:\n",
    "    query = csv_to_node(csv_name)\n",
    "    session.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a CSV of the tables and foreing keys from the original MIMIC III schema:\n",
    "- Obtain foreign key constraints from https://mit-lcp.github.io/mimic-schema-spy/constraints.html\n",
    "- Copy the table into a CSV file. \n",
    "- In a spreadsheet editor, keep only the columns \"Child Column\" and \"Parent Column.\" \n",
    "- Split each of these columns on \".\" into node and foreign key columns. \n",
    "- Save as \"mimic3_relational_schema.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Child Node</th>\n",
       "      <th>Child Foreign Key</th>\n",
       "      <th>Parent Node</th>\n",
       "      <th>Parent Foreign Key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>admissions</td>\n",
       "      <td>subject_id</td>\n",
       "      <td>patients</td>\n",
       "      <td>subject_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>callout</td>\n",
       "      <td>hadm_id</td>\n",
       "      <td>admissions</td>\n",
       "      <td>hadm_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>callout</td>\n",
       "      <td>subject_id</td>\n",
       "      <td>patients</td>\n",
       "      <td>subject_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chartevents</td>\n",
       "      <td>cgid</td>\n",
       "      <td>caregivers</td>\n",
       "      <td>cgid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chartevents</td>\n",
       "      <td>hadm_id</td>\n",
       "      <td>admissions</td>\n",
       "      <td>hadm_id</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Child Node Child Foreign Key Parent Node Parent Foreign Key\n",
       "0   admissions        subject_id    patients         subject_id\n",
       "1      callout           hadm_id  admissions            hadm_id\n",
       "2      callout        subject_id    patients         subject_id\n",
       "3  chartevents              cgid  caregivers               cgid\n",
       "4  chartevents           hadm_id  admissions            hadm_id"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV into a dataframe\n",
    "sql_schema = pd.read_csv('mimic3_relational_schema.csv')\n",
    "\n",
    "# Examine the first five rows\n",
    "sql_schema.iloc[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the normal cypher command to create these relationships would attempt to load too much into RAM at the same time, so the computer can't run the command unless you utilize periodic execution.  \n",
    "See the Neo4j documentation for periodic execution at https://neo4j.com/labs/apoc/4.1/graph-updates/periodic-execution/ to understand the cypher command in the following cell.  \n",
    "\n",
    "Note also that we avoid creating a cartesian product with our MATCH query, which would be very computationally expensive. See Stefan Armbruster's description of how to avoid creating a cartesian product in this scenario at https://community.neo4j.com/t/reliably-create-relationships-on-12million-nodes/22223."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 63: Admissions\n",
      "2 of 63: Callout\n",
      "3 of 63: Callout\n",
      "4 of 63: Chartevents\n",
      "5 of 63: Chartevents\n",
      "6 of 63: Chartevents\n",
      "7 of 63: Chartevents\n",
      "8 of 63: Chartevents\n",
      "9 of 63: Cptevents\n",
      "10 of 63: Cptevents\n",
      "11 of 63: Datetimeevents\n",
      "12 of 63: Datetimeevents\n",
      "13 of 63: Datetimeevents\n",
      "14 of 63: Datetimeevents\n",
      "15 of 63: Datetimeevents\n",
      "16 of 63: Diagnoses_Icd\n",
      "17 of 63: Diagnoses_Icd\n",
      "18 of 63: Diagnoses_Icd\n",
      "19 of 63: Drgcodes\n",
      "20 of 63: Drgcodes\n",
      "21 of 63: Icustays\n",
      "22 of 63: Icustays\n",
      "23 of 63: Inputevents_Cv\n",
      "24 of 63: Inputevents_Cv\n",
      "25 of 63: Inputevents_Cv\n",
      "26 of 63: Inputevents_Cv\n",
      "27 of 63: Inputevents_Mv\n",
      "28 of 63: Inputevents_Mv\n",
      "29 of 63: Inputevents_Mv\n",
      "30 of 63: Inputevents_Mv\n",
      "31 of 63: Inputevents_Mv\n",
      "32 of 63: Labevents\n",
      "33 of 63: Labevents\n",
      "34 of 63: Labevents\n",
      "35 of 63: Microbiologyevents\n",
      "36 of 63: Microbiologyevents\n",
      "37 of 63: Microbiologyevents\n",
      "38 of 63: Microbiologyevents\n",
      "39 of 63: Microbiologyevents\n",
      "40 of 63: Noteevents\n",
      "41 of 63: Noteevents\n",
      "42 of 63: Noteevents\n",
      "43 of 63: Outputevents\n",
      "44 of 63: Outputevents\n",
      "45 of 63: Outputevents\n",
      "46 of 63: Outputevents\n",
      "47 of 63: Outputevents\n",
      "48 of 63: Prescriptions\n",
      "49 of 63: Prescriptions\n",
      "50 of 63: Prescriptions\n",
      "51 of 63: Procedureevents_Mv\n",
      "52 of 63: Procedureevents_Mv\n",
      "53 of 63: Procedureevents_Mv\n",
      "54 of 63: Procedureevents_Mv\n",
      "55 of 63: Procedureevents_Mv\n",
      "56 of 63: Procedures_Icd\n",
      "57 of 63: Procedures_Icd\n",
      "58 of 63: Procedures_Icd\n",
      "59 of 63: Services\n",
      "60 of 63: Services\n",
      "61 of 63: Transfers\n",
      "62 of 63: Transfers\n",
      "63 of 63: Transfers\n"
     ]
    }
   ],
   "source": [
    "# Write a cypher command for each relationship specified in the original\n",
    "# MIMIC III schema\n",
    "count = 0\n",
    "for index, row in sql_schema.iterrows():\n",
    "    child_node = row['Child Node'].title()\n",
    "    child_fk = row['Child Foreign Key']\n",
    "    parent_node = row['Parent Node'].title()\n",
    "    parent_fk = row['Parent Foreign Key']\n",
    "\n",
    "    command = 'CALL apoc.periodic.iterate(\\\"MATCH (cn:{child_node}) MATCH (pn:{parent_node} {{{parent_fk}:cn.{child_fk}}}) RETURN cn, pn\\\", \\\"CREATE (cn)-[:CHILD_OF]->(pn)\\\", {{batchSize:10000, parallel: true, iterateList:true}})'.format(child_node=child_node, parent_node=parent_node, child_fk=child_fk, parent_fk=parent_fk)\n",
    "    session.run(command)\n",
    "    count += 1\n",
    "    print(str(count)+' of 63: '+child_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the connection to the neo4j database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
